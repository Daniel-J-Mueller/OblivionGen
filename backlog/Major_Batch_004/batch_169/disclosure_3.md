# 10003555

## Adaptive Routing Table Sharding with Predictive Prefetching

**Concept:** Extend the power-saving domain approach by dynamically *sharding* the routing table across multiple memory tiers (SRAM, DRAM, persistent memory) based on route access frequency *and predicted future access*. Instead of simply scaling power domains based on total route count, leverage a tiered memory system where frequently accessed routes reside in faster, lower-power memory tiers and infrequently used routes are migrated to slower, higher-capacity tiers. This introduces a predictive element to minimize access latency.

**Specifications:**

**1. Hardware Components:**

*   **Multi-Tier Memory Controller:** A controller capable of managing access to SRAM, DRAM, and persistent memory. Must support transparent data migration between tiers.
*   **Route Access Monitor:** Hardware dedicated to tracking access frequency of individual routes, and aggregate statistics.
*   **Prediction Engine:** A dedicated hardware block utilizing a Markov model or similar predictive algorithm to forecast future route access patterns. This could be a relatively small, specialized co-processor.
*   **Route Sharder/Migrator:** Hardware responsible for physically moving route data between memory tiers based on signals from the Prediction Engine and Route Access Monitor.
*   **Power Domain Controller:** (Existing component from provided patent) â€“ modified to control power to individual memory tiers, not just aggregate power domains.

**2. Data Structures:**

*   **Route Access History Table:** A hardware-maintained table storing recent access timestamps for each route.
*   **Prediction Table:**  Stores predicted access probabilities for each route. Updated continuously by the Prediction Engine.
*   **Tier Assignment Table:** Maps each route to its current memory tier (SRAM, DRAM, Persistent Memory).

**3. Algorithm/Pseudocode:**

```pseudocode
// Initialization
For each route:
  Tier = DRAM // Default tier
  AccessTimestamp = 0
  PredictionScore = 0.5 // Initial prediction

// Main Loop (executed continuously)

// 1. Monitor Route Access
On Route Access Request(routeID):
  Update AccessTimestamp(routeID)
  Increment AccessCount(routeID)

// 2. Prediction Engine Update
For each route:
  PredictionScore = UpdatePrediction(routeID, AccessHistory, PredictionScore)
    // UpdatePrediction uses a Markov model or similar
    // to predict future access probability based on history

// 3. Tier Assignment
For each route:
  If PredictionScore > HighThreshold:
    Tier = SRAM  // Move to fastest tier
  Else If PredictionScore < LowThreshold:
    Tier = PersistentMemory // Move to slowest tier
  Else:
    Tier = DRAM // Remain in default tier

  If CurrentTier != Tier:
    MigrateRouteData(routeID, CurrentTier, Tier)

// 4. Power Management
AdjustPowerToMemoryTier(SRAM, SRAMOccupancy)
AdjustPowerToMemoryTier(DRAM, DRAMOccupancy)
AdjustPowerToMemoryTier(PersistentMemory, PersistentMemoryOccupancy)
```

**4. Migration Strategy:**

*   Data migration should be performed in the background, minimizing impact on forwarding performance.
*   Migration could be triggered by reaching a specific occupancy threshold in a memory tier.
*   Prioritize migration of frequently accessed routes during periods of low network traffic.
*   Write-back cache mechanisms should be employed to ensure data consistency.

**5. Power Optimization:**

*   Dynamic Voltage and Frequency Scaling (DVFS) applied to individual memory tiers based on occupancy and access rates.
*   Power gating for inactive memory banks within each tier.
*   Adaptive refresh rates for DRAM and persistent memory.

**Novelty:** This approach moves beyond simple power domain scaling to introduce dynamic tiering of routing table data based on predicted access patterns, offering a more granular and efficient power/performance tradeoff. The predictive element is key, proactively moving routes to the optimal memory tier before access is required.