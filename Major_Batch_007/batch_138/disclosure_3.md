# 10121182

## Adaptive Media Environment - "Sonic Bloom"

**Concept:** A dynamic media environment that adjusts ambient lighting and subtle haptic feedback *in real-time* based on the BPM and emotional valence (determined via audio analysis) of the currently playing media, effectively "blooming" the user's environment with synchronized sensory input. This extends beyond simple visualizers or beat-matched lighting, aiming for a holistic, immersive experience.

**Specs:**

*   **Hardware:**
    *   Smart Lighting System: Full-spectrum LED array capable of precise color and intensity control. Minimum 12 independent zones.
    *   Haptic Transducers: Low-frequency transducers embedded in furniture (chairs, sofas) and potentially floor surfaces.
    *   Audio Analysis Module: High-fidelity audio input jack or wireless connection to media source.  Dedicated DSP chip for real-time BPM and emotional valence detection.
    *   Central Control Unit: Embedded system (Raspberry Pi or equivalent) to manage audio analysis, lighting control, and haptic feedback. Wi-Fi/Bluetooth connectivity for integration with existing smart home ecosystems.
*   **Software:**
    *   BPM Detection Algorithm: Robust algorithm capable of accurately detecting BPM across various music genres. Tolerance for complex arrangements and tempo changes.
    *   Emotional Valence Analysis: Machine learning model trained to identify emotional valence (positive, negative, neutral) from audio features (e.g., key, mode, harmonic complexity).
    *   Sensory Mapping Engine: Customizable engine to map BPM and emotional valence to specific lighting and haptic patterns.
        *   BPM to Lighting: Higher BPM = faster lighting pulses or color transitions. Lower BPM = slower, more subtle effects.
        *   Emotional Valence to Color: Positive valence = warmer colors (yellows, oranges). Negative valence = cooler colors (blues, purples). Neutral = white or grayscale.
        *   BPM & Valence to Haptics:  BPM dictates haptic pulse frequency. Valence dictates haptic intensity and texture (e.g., gentle vibration for positive, sharper pulses for negative).
    *   User Interface: Mobile app for customization of sensory mappings, preset selection, and integration with music streaming services.
    *   API: Open API for developers to create custom mappings and integrate with other smart home devices.

**Pseudocode (Sensory Mapping Engine):**

```
function map_sensory_input(bpm, valence) {
  // Normalize BPM and Valence values to a 0-1 range
  normalized_bpm = map(bpm, 60, 200, 0, 1); // Assuming BPM range of 60-200
  normalized_valence = map(valence, -1, 1, 0, 1); // Valence range of -1 to 1

  // Calculate Lighting Parameters
  lighting_hue = map(normalized_valence, 0, 1, 120, 60); // Blue to Orange
  lighting_saturation = map(normalized_bpm, 0, 1, 50, 100);
  lighting_brightness = map(normalized_bpm, 0, 1, 20, 255);

  // Calculate Haptic Parameters
  haptic_frequency = normalized_bpm * 2; // Double BPM for haptic pulses
  haptic_intensity = normalized_valence * 100; // Scale intensity by valence

  // Apply parameters to lighting and haptic systems
  set_lighting_hue(lighting_hue);
  set_lighting_saturation(lighting_saturation);
  set_lighting_brightness(lighting_brightness);
  set_haptic_frequency(haptic_frequency);
  set_haptic_intensity(haptic_intensity);
}
```

**Novelty:** Extends media recommendation/matching based on BPM to *actively* modify the user's physical environment. This moves beyond passive listening/watching to a fully immersive experience where the environment responds in real-time to the emotional content and rhythm of the media. It isnâ€™t simply matching visualizers but crafting a dynamic, synesthetic feedback loop.